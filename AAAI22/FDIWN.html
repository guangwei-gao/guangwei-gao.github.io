<!DOCTYPE html>
<html>
<head>
<title>AAAI22_FDIWN</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

<body>
<h3 align="center"><i><font size="4" face="Palatino Linotype">36th AAAI Conference on Artificial Intelligence (AAAI) 2022</font></i></h3>

<table align="center">
<td align="center">
<h1>Feature Distillation Interaction Weighting Network for <br> Lightweight Image Super-Resolution</h1>
<h3>
	<a href="https://guangweigao.github.io/" target="_blank"><font size="4"><b>Guangwei Gao</b></font></a><sup><font size="3">1†</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4"><b>Wenjie Li</b></font></a><sup><font size="3">1†</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="https://junchenglee.com/" target="_blank"><font size="4"><b>Juncheng Li</b></font></a><sup><font size="3">2*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4">Fei Wu</font><sup><font size="3">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4">Huimin Lu</font><sup><font size="3">3</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="4">Yi Yu</font><sup><font size="3">4</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
</h3>

<sup><font size="2">1</font></sup>
<b><a><font size="4">Nanjing University of Posts and Telecommunications</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">2</font></sup>
<b><a><font size="4">The Chinese University of Hong Kong</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp; <br>
<sup><font size="2">3</font></sup>
<b><a><font size="4">Kyushu Institute of Technology</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">4</font></sup>
<b><a><font size="4">National Institute of Informatics</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;

<br>
<br>&nbsp;
	<b><a><font size="3"> †Co-ﬁrst authors, *Corresponding author &nbsp;&nbsp;&nbsp;&nbsp; Contact us: {csggao,cvjunchengli}@gmail.com, liwj0824@163.com</font></a></b>
<br>

</td>
</table>

<!--
<br><br>
<table align="center">
<tr>
	<td align="center"><embed src="head.png" width="600"></td>
</tr>
</table>-->


<br>
<h2><p><font size="6"><b>Abstract</b></font></p></h2>
<hr/>
<p><font size="4" face="Palatino Linotype">Convolutional neural networks based single-image super-resolution (SISR) has made great progress in recent years. However, it is difficult to apply these methods to real-world scenarios due to the computational and memory cost. Meanwhile, how to take full advantage of the intermediate features under the constraints of limited parameters and calculations is also a huge challenge. To alleviate these issues, we propose a lightweight yet efficient Feature Distillation Interaction Weighted Network (FDIWN). Specifically, FDIWN utilizes a series of specially designed Feature Shuffle Weighted Groups (FSWG) as the backbone, and several novel mutual Wide-residual Distillation Interaction Blocks (WDIB) form an FSWG. In addition, Wide Identical Residual Weighting (WIRW) units and Wide Convolutional Residual Weighting (WCRW) units are introduced into WDIB for better feature distillation. Moreover, a Wide-Residual Distillation Connection (WRDC) framework and a Self-Calibration Fusion (SCF) unit are proposed to interact features with different scales more flexibly and efficiently.
Extensive experiments show that our FDIWN is superior to other models to strike a good balance between model performance and efficiency. The code is available at https://github.com/IVIPLab/FDIWN.
</font></p>

<!--
<br>
<h2><p><font size="6"><b>Motivation</b></font></p></h2>
<hr/>
<table align="center">
</table>
<p><font size="4" face="Palatino Linotype">As shown in the figure below, the inner areas of the boxes with the same color are similar to each other. Therefore, these similar image patches can be used as reference images for each other, so that the texture details of the certain patch can be restored with reference patches. Inspired by this, we introduce the Transformer into the SISR task since it has a strong feature expression ability to model such a long-term dependency in the image. In recent years, some Vision-Transformer have been proposed for computer vision tasks. However, these methods often occupy heavy GPU memory, which greatly limits their ﬂexibility and application scenarios. Moreover, these methods cannot be directly transferred to SISR since the image restoration task often take a larger resolution image as input, which will take up huge memory. To solve this, we aim to explore a more efﬁcient vision-Transformer for SISR.
</font></p>
<table align="center">
<tr>
	<td align="center"><img border=0 width=600 src="EP.png"></td>
</tr>
<tr>
<td align="center">Examples of similar patches in images. These similar patches can help restore details from each other.</td>
</tr>
</table>-->

<br>
<h2><p><font size="6"><b>FDIWN</b></font></p></h2>
<table align="center">
<hr/>
<tr>
	<td align="center"><img border=0 width=900 src="FDIWN.png"></td>
</tr>
<br>	
<tr>
	<td align="center">The architecture of the proposed Feature Distillation Interaction Weighting Network (FDIWN).</td>
</tr>
</table>


<table align="center">
<hr/>
<tr>
	<td align="center"><img border=0 width=900 src="WDIB.png"></td>
</tr>
<br>
<tr>
	<td align="center">The structure of the proposed Wide-residual Distillation Interaction Block (WDIB). Conv1 and Conv3 represent the convolutional layer with the kernel size of 1 and 3, respectively.</td>
</tr>
</table>




<br>
<h2><p><font size="6"><b>Visual Results</b></font></p></h2>

<table align="center">
<hr/>
<tr>
	<td align="center"><img border=0 width=900 src="Speed.png"></td>
</tr>
<br>
<tr>
	<td align="center">Inference speed study on Set14 (left) and Urban100 (right) with x2 SR.</td>
</tr>
</table>


<hr/>
<table align="center">
<tr>
	<td align="center"><img border=0 width=900 src="koutu.png"></td>
</tr>
	<br>
<tr>
	<td align="center">Visual comparisons on the Urban100 dataset.</td>
</tr>
</table>




<br>
<h2><p><font size="6"><b>PSNR/SSIM Results</b></font></p></h2>
<hr/>
<table align="center">
<tr>
	<td align="center"><img border=0 width=900 src="PSNR_SSIM.png"></td>
</tr>
</table>



<br>
<h2><p><font size="6"><b>Downloads</b></font></p></h2>
<hr/>
<div align="left">
		<table>						
		<tr align="left">
		<td>
			<font size="4">Paper</font>
		</td>
		<td>
			<font size="4">: <a href="https://arxiv.org/abs/2112.08655" target="_blank">[ Paper ]</a></font>
		</td>
		</tr>
			
       <tr align="left">
		<td>
			<font size="4">Supp Material</font>
		</td>
		<td>
			<font size="4">: <a href="https://pan.baidu.com/s/1XwdEjCgiPfHTumGU4aWKiQ" target="_blank">[ Supplementary Material(提取码:9168) ]</a></font>
		</td>
	    </tr>
					
		<tr align="left">
		<td>
			<font size="4">Source Code</font>
		</td>
		<td>
			<font size="4">: <a href="https://github.com/IVIPLab/FDIWN" target="_blank">[ Code ]</a> </font>
		</td>
		</tr>	
			
			
		</table>
</div>

<!--
<h2><p><font size="6" color="black"><b>Statement</b></font></p></h2>
<hr/>
<font size="3">
The original title of this paper was "Efficient Transformer for Single Image Super-Resolution". </br>
The final version of this paper is "Transformer for Single Image Super-Resolution". 
</font>-->


<h2><p><font size="6" color="black"><b>BibTex</b></font></p></h2>
<hr/>
<font size="3">
@InProceedings{gao2021feature,<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = {Feature Distillation Interaction Weighting Network for Lightweight Image Super-Resolution},<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = {Gao, Guangwei and Li, Wenjie and Li, Juncheng and Wu, Fei and Lu, Huimin and Yu, Yi},<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = {AAAI},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = {2022}<br>
}
</font>


</body>

</html>
